# ğŸ“ Project Structure - Ultralytics Agricultural Weed Detection

**Last Updated**: December 16, 2025

This document describes the organization of the Ultralytics agricultural weed detection project.

---

## ğŸ—‚ï¸ Root Directory Overview

```
ultralytics/                          # Project root
â”œâ”€â”€ .claude.md                        # ğŸ“‹ AI assistant project documentation
â”œâ”€â”€ PROJECT_LOG.md                    # ğŸ“… Session log with detailed history
â”œâ”€â”€ PROJECT_STRUCTURE.md              # ğŸ“ This file - directory organization
â”œâ”€â”€ README.md                         # ğŸŒ¾ Main README (agricultural focus)
â”œâ”€â”€ CONTRIBUTING.md                   # ğŸ¤ Contribution guidelines
â”œâ”€â”€ LICENSE                           # âš–ï¸ AGPL-3.0 license
â”œâ”€â”€ CITATION.cff                      # ğŸ“š Citation information
â”œâ”€â”€ pyproject.toml                    # ğŸ“¦ Python project configuration
â”œâ”€â”€ mkdocs.yml                        # ğŸ“– Documentation site config
â”œâ”€â”€ yolo11{n,s,m,l,x}.pt             # ğŸ¤– Pre-trained YOLO11 models (24-114 MB)
â”‚
â”œâ”€â”€ configs/                          # âš™ï¸ Dataset configurations
â”œâ”€â”€ datasets/                         # ğŸŒ± Agricultural datasets
â”œâ”€â”€ scripts/                          # ğŸ Custom training & evaluation scripts
â”œâ”€â”€ experiments/                      # ğŸ“Š Training results & model weights
â”œâ”€â”€ documents/                        # ğŸ“„ Experiment reports (Spanish)
â”œâ”€â”€ external_review/                  # ğŸ” External scripts analysis
â”‚
â”œâ”€â”€ ultralytics/                      # ğŸ—ï¸ Core YOLO framework (DO NOT MODIFY)
â”œâ”€â”€ docs/                             # ğŸ“– Ultralytics documentation
â”œâ”€â”€ examples/                         # ğŸ’¡ Usage examples
â”œâ”€â”€ tests/                            # âœ… Test suite
â”œâ”€â”€ docker/                           # ğŸ³ Docker configurations
â”œâ”€â”€ figures/                          # ğŸ“ˆ Visualization outputs
â””â”€â”€ .github/                          # ğŸ”§ GitHub workflows & templates
```

---

## ğŸŒ¾ Agricultural Extensions (Our Custom Code)

### 1. `configs/` - Dataset Configurations
**Purpose**: YAML files defining dataset paths, class names, and metadata.

```
configs/
â”œâ”€â”€ lentils_v1.yaml                   # Legacy 4-class configuration
â”‚   # Classes: AMBEL, LENCU, POLAV, POLPE
â”‚   # Original multi-model benchmark dataset
â”‚
â”œâ”€â”€ merge_varios_cultivos.yaml        # 6-class multi-crop unified model
â”‚   # Classes: AMBEL, LENCU, LOLSS, POLAV, POLPE, RAPRA
â”‚   # 5,765 train / 181 val / 140 test images
â”‚   # mAP50: 81.9% (YOLO11l)
â”‚
â”œâ”€â”€ sr_dauca.yaml                     # Single-class DAUCA specialist
â”‚   # Classes: DAUCA (Daucus carota - Wild carrot)
â”‚   # 70 train / 3 val / 1 test images
â”‚   # mAP50: 86.4%, Precision: 84.6% (YOLO11l)
â”‚
â””â”€â”€ ultralytics.code-workspace        # VS Code workspace settings
```

**File Format**:
```yaml
train: /path/to/dataset/train/images
val: /path/to/dataset/valid/images
test: /path/to/dataset/test/images
nc: 6                                  # Number of classes
names: ['AMBEL', 'LENCU', 'LOLSS', 'POLAV', 'POLPE', 'RAPRA']
roboflow: fia2024/mergevarios          # Roboflow project reference
```

---

### 2. `scripts/` - Custom Training & Evaluation Scripts
**Purpose**: Automation scripts for experiments, evaluation, and monitoring.

```
scripts/
â”œâ”€â”€ run_experiments.py                # ğŸš€ Multi-model orchestrator
â”‚   # Trains all 5 YOLO11 variants (n, s, m, l, x) sequentially
â”‚   # Optimized batch sizes per model for dual RTX 4090
â”‚   # DLM2 methodology: ALL augmentation disabled
â”‚   # Usage: python scripts/run_experiments.py
â”‚
â”œâ”€â”€ train_sr_dauca.py                 # ğŸ¯ DAUCA specialist training
â”‚   # Single-model training for sr_dauca dataset
â”‚   # YOLO11l with DLM2 parameters
â”‚   # Usage: python scripts/train_sr_dauca.py
â”‚
â”œâ”€â”€ train_merge_varios.py             # ğŸŒ¾ Multi-crop training
â”‚   # Single-model training for merge_varios_cultivos
â”‚   # YOLO11l with DLM2 parameters
â”‚   # Usage: python scripts/train_merge_varios.py
â”‚
â”œâ”€â”€ evaluate_models.py                # ğŸ“Š Batch evaluation
â”‚   # Evaluates all completed experiments on test set
â”‚   # Generates per-class metrics (precision, recall, F1, mAP50)
â”‚   # Outputs: CSV files with class-wise breakdown
â”‚   # Usage: python scripts/evaluate_models.py
â”‚
â”œâ”€â”€ evaluate_sr_dauca.py              # ğŸ” DAUCA evaluation
â”‚   # Detailed evaluation on val and test splits
â”‚   # Generates confusion matrix, per-class metrics
â”‚   # Usage: python scripts/evaluate_sr_dauca.py
â”‚
â”œâ”€â”€ evaluate_merge_varios.py          # ğŸ” Multi-crop evaluation
â”‚   # Similar to evaluate_sr_dauca for merge_varios dataset
â”‚   # Usage: python scripts/evaluate_merge_varios.py
â”‚
â”œâ”€â”€ compare_results.py                # ğŸ“ˆ Cross-experiment comparison
â”‚   # Compiles metrics across all experiments
â”‚   # Generates comparison tables (CSV)
â”‚   # Usage: python scripts/compare_results.py
â”‚
â”œâ”€â”€ plot_results.py                   # ğŸ“Š Visualization
â”‚   # Plots training curves (loss, mAP, precision, recall)
â”‚   # Usage: python scripts/plot_results.py <experiment_path>
â”‚
â”œâ”€â”€ live_plot.py                      # ğŸ“‰ Real-time monitoring
â”‚   # Live training curve plotting during experiments
â”‚   # Monitors results.csv for updates
â”‚   # Usage: python scripts/live_plot.py <experiment_path>
â”‚
â””â”€â”€ live_dashboard.py                 # ğŸ–¥ï¸ GPU monitoring
    # Real-time GPU utilization dashboard
    # Uses pynvml for GPU stats (temperature, memory, utilization)
    # Usage: python scripts/live_dashboard.py
```

**Key Features**:
- **DLM2 Compliance**: All training scripts disable internal augmentation
- **Multi-GPU Support**: DDP with device selection `0,1`
- **Batch Size Optimization**: Tailored per model for 2Ã—RTX 4090 (48GB total)
- **Comprehensive Logging**: JSON summaries, CSV metrics, TensorBoard

---

### 3. `datasets/` - Agricultural Datasets
**Purpose**: Image datasets with YOLO format annotations (train/val/test splits).

```
datasets/
â”œâ”€â”€ lentils_v1/                       # Legacy 4-class dataset
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ images/                   # Training images
â”‚   â”‚   â””â”€â”€ labels/                   # YOLO format .txt labels
â”‚   â”œâ”€â”€ valid/                        # Validation split
â”‚   â”œâ”€â”€ test/                         # Test split
â”‚   â”œâ”€â”€ data.yaml                     # Dataset config (auto-generated)
â”‚   â””â”€â”€ README.roboflow.txt           # Roboflow export info
â”‚
â”œâ”€â”€ merge_varios_cultivos/            # Multi-crop unified dataset
â”‚   â”œâ”€â”€ train/                        # 5,765 images
â”‚   â”œâ”€â”€ valid/                        # 181 images
â”‚   â”œâ”€â”€ test/                         # 140 images
â”‚   â”œâ”€â”€ data.yaml
â”‚   â””â”€â”€ README.roboflow.txt
â”‚
â”œâ”€â”€ sr_dauca/                         # DAUCA specialist dataset
â”‚   â”œâ”€â”€ train/                        # 70 images (SMALL!)
â”‚   â”œâ”€â”€ valid/                        # 3 images
â”‚   â”œâ”€â”€ test/                         # 1 image
â”‚   â”œâ”€â”€ data.yaml
â”‚   â””â”€â”€ README.roboflow.txt
â”‚
â””â”€â”€ sr_dauca_extra/                   # Additional DAUCA samples
    â”œâ”€â”€ StaRosa_DAUCA/                # Raw drone imagery
    â””â”€â”€ StaRosa_DAUCA-20251211T.../   # Extracted patches
```

**Species Mapping**:
| Code | Scientific Name | Common Name | Type |
|------|----------------|-------------|------|
| AMBEL | *Ambrosia artemisiifolia* | Ragweed | Weed |
| LENCU | *Lens culinaris* | Lentil | Crop |
| LOLSS | *Lolium* spp. | Ryegrass | Weed |
| POLAV | *Polygonum aviculare* | Knotweed | Weed |
| POLPE | *Polygonum persicaria* | Smartweed | Weed |
| RAPRA | *Raphanus raphanistrum* | Wild radish | Weed |
| DAUCA | *Daucus carota* | Wild carrot | Weed |

**Label Format** (YOLO):
```
<class_id> <x_center> <y_center> <width> <height>
```
All coordinates normalized to [0, 1].

---

### 4. `experiments/` - Training Results & Weights
**Purpose**: Outputs from training runs, organized by dataset and model configuration.

```
experiments/
â”œâ”€â”€ comparison_report.csv             # Cross-experiment comparison
â”‚
â”œâ”€â”€ lentils_v1_dlm2/                  # DLM2 methodology runs
â”‚   â”œâ”€â”€ live_dashboard.png            # GPU monitoring screenshot
â”‚   â”œâ”€â”€ test_metrics_by_class.csv     # Per-class test metrics
â”‚   â”œâ”€â”€ yolo11n_img1024_ep50_noaug/   # Nano model results
â”‚   â”œâ”€â”€ yolo11s_img1024_ep50_noaug/   # Small model results
â”‚   â”œâ”€â”€ yolo11m_img1024_ep50_noaug/   # Medium model results
â”‚   â”œâ”€â”€ yolo11l_img1024_ep50_noaug/   # Large model results
â”‚   â””â”€â”€ yolo11x_img1024_ep50_noaug/   # Extra-large model results
â”‚
â”œâ”€â”€ merge_varios_cultivos/
â”‚   â”œâ”€â”€ experiment_log.md             # Experiment notes & findings
â”‚   â”œâ”€â”€ final_evaluation_report.csv   # Test set metrics
â”‚   â”œâ”€â”€ eval_val/                     # Validation evaluation outputs
â”‚   â”œâ”€â”€ eval_test/                    # Test evaluation outputs
â”‚   â”œâ”€â”€ live_dashboard.png
â”‚   â””â”€â”€ yolo11l_img1024_ep50_noaug/
â”‚       â”œâ”€â”€ weights/
â”‚       â”‚   â”œâ”€â”€ best.pt               # Best model (by mAP50)
â”‚       â”‚   â””â”€â”€ last.pt               # Last epoch
â”‚       â”œâ”€â”€ results.csv               # Training metrics per epoch
â”‚       â”œâ”€â”€ results.png               # Training curves
â”‚       â”œâ”€â”€ confusion_matrix.png      # Confusion matrix
â”‚       â”œâ”€â”€ F1_curve.png              # F1 vs confidence
â”‚       â”œâ”€â”€ P_curve.png               # Precision vs confidence
â”‚       â”œâ”€â”€ R_curve.png               # Recall vs confidence
â”‚       â”œâ”€â”€ PR_curve.png              # Precision-Recall curve
â”‚       â””â”€â”€ args.yaml                 # Training arguments used
â”‚
â””â”€â”€ sr_dauca/
    â”œâ”€â”€ experiment_log.md
    â”œâ”€â”€ final_evaluation_report.csv
    â”œâ”€â”€ eval_val/                     # Validation evaluation
    â”œâ”€â”€ eval_test/                    # Test evaluation
    â”œâ”€â”€ eval_val_recheck/             # Re-validation runs
    â”œâ”€â”€ live_dashboard.png
    â””â”€â”€ yolo11l_img1024_ep50_noaug/
        â””â”€â”€ [same structure as above]
```

**Important**:
- âš ï¸ **DO NOT COMMIT** `experiments/` to git (too large, excluded in .gitignore)
- Model weights: `best.pt` (20-100 MB), `last.pt`
- Training history: `results.csv` tracks loss, mAP, precision, recall per epoch

---

### 5. `documents/` - Experiment Reports
**Purpose**: Detailed Spanish-language reports summarizing experimental results.

```
documents/
â”œâ”€â”€ resumen_experiencias_multicultivo_2025.md
â”‚   # Multi-crop detection summary (December 2025)
â”‚   # YOLO11l results: 81.9% mAP50, per-class breakdown
â”‚   # Methodology: DLM2, dataset characteristics
â”‚   # Limitations: POLAV class imbalance (57% mAP50)
â”‚   # Recommendations for improvement
â”‚
â””â”€â”€ resumen_experiencias_dauca_2025.md
    # DAUCA specialist summary (December 2025)
    # YOLO11l results: 86.4% mAP50, 84.6% precision
    # Geographic context: Santa Rosa region
    # Integration with Sentinel-2 NDVI validation
    # Spatial autocorrelation analysis (Moran's I = 0.667)
    # Recommendations: Expand dataset beyond 70 images
```

**Report Contents**:
- Methodology description (DLM2, hardware, hyperparameters)
- Dataset characteristics (size, distribution, imbalance)
- Training configuration (batch size, epochs, augmentation = disabled)
- Results tables (precision, recall, F1, mAP50, mAP50-95)
- Per-class performance breakdown
- Confusion matrices and visualizations
- Limitations and challenges
- Recommendations for future work

---

### 6. `external_review/` - External Scripts Analysis
**Purpose**: Collection and review of useful scripts from community repositories.

```
external_review/
â”œâ”€â”€ INVENTORY.md                      # ğŸ“‹ Comprehensive script analysis
â”‚   # 420+ lines of detailed review
â”‚   # Script-by-script breakdown
â”‚   # Priority rankings and integration recommendations
â”‚   # Code examples and use cases
â”‚
â”œâ”€â”€ maaferna_INIA_scripts/            # Python scripts (172 KB)
â”‚   â”œâ”€â”€ geo_data_utils.py             # â­â­â­ UTMâ†”GPS, GeoJSON generation
â”‚   â”œâ”€â”€ utils.py                      # â­â­â­ Visualization, EXIF, model finder
â”‚   â”œâ”€â”€ predict_yolo.py               # â­â­â­ SAHI sliced inference
â”‚   â”œâ”€â”€ validation_yolo.py            # â­â­ Single-image validation
â”‚   â”œâ”€â”€ yolo_training.py              # â­â­ Multi-run training
â”‚   â”œâ”€â”€ clearml_utils.py              # â­ Experiment tracking
â”‚   â”œâ”€â”€ converted_to_utm_from_disk_F.py  # â­ GPSâ†’UTM batch conversion
â”‚   â”œâ”€â”€ main.py                       # CLI orchestrator
â”‚   â”œâ”€â”€ utils_prompts.py              # Interactive prompts
â”‚   â””â”€â”€ config.py                     # Config loader
â”‚
â”œâ”€â”€ maaferna_INIA_docs/               # Documentation (8 files)
â”‚   â”œâ”€â”€ sahi-implementation.md        # SAHI sliced inference guide
â”‚   â”œâ”€â”€ clearML-settings.md           # ClearML setup
â”‚   â”œâ”€â”€ datasets-distribution.md      # Dataset split methodology
â”‚   â”œâ”€â”€ experimentation-program.md    # Experiment planning
â”‚   â”œâ”€â”€ inference-time-documentation.md  # Benchmarks
â”‚   â”œâ”€â”€ procedure-calculate-f1.md     # F1 calculation
â”‚   â”œâ”€â”€ procedure-selection-best.md   # Best model selection
â”‚   â””â”€â”€ script-training.md            # Training docs
â”‚
â”œâ”€â”€ maaferna_INIA_README.md           # Original repo README
â”œâ”€â”€ data_416.yaml                     # Sample configs
â”œâ”€â”€ data_640.yaml
â”œâ”€â”€ data_1024.yaml
â””â”€â”€ data_2048.yaml
```

**Key Findings**:
1. **SAHI Integration** - Critical for 1024px+ high-res images
2. **Geospatial Tools** - GeoJSON export, UTM conversion
3. **Enhanced Visualization** - Minimalistic labels (confidence only + legend)
4. **Best Model Finder** - Automated model selection by mAP50
5. **Multi-run Strategy** - Train 5x with different seeds, pick best

**Status**: ğŸ“‹ Reviewed, awaiting integration (Session 3)

---

## ğŸ—ï¸ Core Ultralytics Framework (Upstream)

### 7. `ultralytics/` - Main Framework
**Purpose**: Core YOLO implementation (DO NOT MODIFY - maintain upstream compatibility)

```
ultralytics/
â”œâ”€â”€ __init__.py                       # Package initialization
â”œâ”€â”€ cfg/                              # Default configurations
â”‚   â”œâ”€â”€ __init__.py                   # Config system
â”‚   â”œâ”€â”€ datasets/                     # Dataset configs (COCO, VOC, etc.)
â”‚   â”œâ”€â”€ models/                       # Model architectures (YAML)
â”‚   â”‚   â”œâ”€â”€ 11/                       # YOLO11 variants
â”‚   â”‚   â”œâ”€â”€ v8/                       # YOLO v8 variants
â”‚   â”‚   â”œâ”€â”€ v9/                       # YOLO v9 variants
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ trackers/                     # Tracking configs
â”‚
â”œâ”€â”€ data/                             # Data loading & augmentation
â”‚   â”œâ”€â”€ augment.py                    # Augmentation transforms
â”‚   â”œâ”€â”€ base.py                       # Base dataset class
â”‚   â”œâ”€â”€ build.py                      # Dataset builders
â”‚   â”œâ”€â”€ loaders.py                    # Data loaders
â”‚   â””â”€â”€ utils.py                      # Data utilities
â”‚
â”œâ”€â”€ engine/                           # Training & inference engines
â”‚   â”œâ”€â”€ trainer.py                    # Main training loop
â”‚   â”œâ”€â”€ validator.py                  # Validation logic
â”‚   â”œâ”€â”€ predictor.py                  # Inference engine
â”‚   â”œâ”€â”€ exporter.py                   # Model export (ONNX, TF, etc.)
â”‚   â”œâ”€â”€ tuner.py                      # Hyperparameter tuning
â”‚   â””â”€â”€ results.py                    # Result handling
â”‚
â”œâ”€â”€ models/                           # Model implementations
â”‚   â”œâ”€â”€ yolo/                         # YOLO models
â”‚   â”‚   â”œâ”€â”€ detect/                   # Detection models
â”‚   â”‚   â”œâ”€â”€ segment/                  # Segmentation models
â”‚   â”‚   â”œâ”€â”€ classify/                 # Classification models
â”‚   â”‚   â”œâ”€â”€ pose/                     # Pose estimation
â”‚   â”‚   â””â”€â”€ obb/                      # Oriented bounding boxes
â”‚   â”œâ”€â”€ sam/                          # Segment Anything Model (SAM)
â”‚   â”œâ”€â”€ fastsam/                      # Fast SAM
â”‚   â”œâ”€â”€ rtdetr/                       # RT-DETR
â”‚   â””â”€â”€ nas/                          # Neural Architecture Search
â”‚
â”œâ”€â”€ nn/                               # Neural network modules
â”‚   â”œâ”€â”€ modules/                      # Building blocks
â”‚   â”‚   â”œâ”€â”€ block.py                  # Convolution blocks
â”‚   â”‚   â”œâ”€â”€ conv.py                   # Convolution layers
â”‚   â”‚   â”œâ”€â”€ head.py                   # Detection heads
â”‚   â”‚   â””â”€â”€ transformer.py            # Transformer blocks
â”‚   â”œâ”€â”€ tasks.py                      # Model task definitions
â”‚   â”œâ”€â”€ autobackend.py                # Multi-backend support
â”‚   â””â”€â”€ text_model.py                 # Text models
â”‚
â”œâ”€â”€ utils/                            # Utility functions
â”‚   â”œâ”€â”€ callbacks/                    # Training callbacks
â”‚   â”œâ”€â”€ export/                       # Export utilities
â”‚   â”œâ”€â”€ benchmarks.py                 # Benchmarking
â”‚   â”œâ”€â”€ checks.py                     # System checks
â”‚   â”œâ”€â”€ downloads.py                  # Model/data downloads
â”‚   â”œâ”€â”€ files.py                      # File operations
â”‚   â”œâ”€â”€ logger.py                     # Logging
â”‚   â”œâ”€â”€ metrics.py                    # Evaluation metrics
â”‚   â”œâ”€â”€ ops.py                        # Operations (NMS, etc.)
â”‚   â”œâ”€â”€ plotting.py                   # Visualization
â”‚   â”œâ”€â”€ torch_utils.py                # PyTorch utilities
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ solutions/                        # Pre-built solutions
â”‚   â”œâ”€â”€ object_counter.py             # Object counting
â”‚   â”œâ”€â”€ heatmaps.py                   # Heatmap generation
â”‚   â”œâ”€â”€ distance_calculation.py       # Distance measurement
â”‚   â”œâ”€â”€ speed_estimation.py           # Speed tracking
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ trackers/                         # Object tracking
â”‚   â”œâ”€â”€ bot_sort.py                   # BoT-SORT tracker
â”‚   â”œâ”€â”€ byte_tracker.py               # ByteTrack
â”‚   â””â”€â”€ utils/                        # Tracking utilities
â”‚
â””â”€â”€ hub/                              # Ultralytics HUB integration
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ auth.py                       # Authentication
    â””â”€â”€ session.py                    # Cloud sessions
```

**Important**:
- âœ… **USE** these modules in your scripts (import from ultralytics)
- âŒ **DO NOT MODIFY** core framework files
- ğŸ”„ **PULL UPDATES** regularly: `git fetch upstream && git merge upstream/main`

---

### 8. `docs/` - Documentation
**Purpose**: Ultralytics documentation site (MkDocs-based).

```
docs/
â”œâ”€â”€ en/                               # English documentation
â”‚   â”œâ”€â”€ datasets/                     # Dataset guides
â”‚   â”œâ”€â”€ guides/                       # How-to guides
â”‚   â”œâ”€â”€ models/                       # Model documentation
â”‚   â”œâ”€â”€ modes/                        # Operation modes (train, val, predict)
â”‚   â”œâ”€â”€ tasks/                        # Task types (detect, segment, classify)
â”‚   â”œâ”€â”€ integrations/                 # Third-party integrations
â”‚   â””â”€â”€ reference/                    # API reference
â”œâ”€â”€ macros/                           # Documentation macros
â””â”€â”€ overrides/                        # Custom theme elements
```

**Access**: https://docs.ultralytics.com/

---

### 9. `examples/` - Usage Examples
**Purpose**: Example scripts demonstrating various use cases.

```
examples/
â”œâ”€â”€ tutorial.ipynb                    # Quickstart tutorial
â”œâ”€â”€ heatmaps.ipynb                    # Heatmap visualization
â”œâ”€â”€ object_counting.ipynb             # Object counting
â”œâ”€â”€ object_tracking.ipynb             # Multi-object tracking
â”œâ”€â”€ hub.ipynb                         # Ultralytics HUB usage
â”‚
â”œâ”€â”€ YOLOv8-ONNXRuntime/               # ONNX Runtime inference
â”œâ”€â”€ YOLOv8-OpenCV-ONNX-Python/        # OpenCV + ONNX
â”œâ”€â”€ YOLOv8-CPP-Inference/             # C++ inference
â”œâ”€â”€ YOLOv8-SAHI-Inference-Video/      # SAHI sliced inference example
â”œâ”€â”€ RTDETR-ONNXRuntime-Python/        # RT-DETR inference
â””â”€â”€ ...                               # Many more examples
```

**Relevant Example**: `YOLOv8-SAHI-Inference-Video/` - Study for Session 3 SAHI integration!

---

### 10. `tests/` - Test Suite
**Purpose**: Automated tests for framework validation.

```
tests/
â”œâ”€â”€ test_python.py                    # Python API tests
â”œâ”€â”€ test_cli.py                       # CLI tests
â”œâ”€â”€ test_exports.py                   # Export functionality tests
â”œâ”€â”€ test_solutions.py                 # Solutions tests
â””â”€â”€ ...
```

**Usage**: `pytest tests/` (run all tests)

---

### 11. `docker/` - Docker Configurations
**Purpose**: Containerization for reproducible environments.

```
docker/
â”œâ”€â”€ Dockerfile                        # Standard CUDA image
â”œâ”€â”€ Dockerfile-cpu                    # CPU-only image
â”œâ”€â”€ Dockerfile-arm64                  # ARM architecture (Apple Silicon)
â”œâ”€â”€ Dockerfile-jetson-jetpack{4,5,6}  # NVIDIA Jetson
â”œâ”€â”€ Dockerfile-conda                  # Conda environment
â””â”€â”€ ...
```

**Usage**: `docker build -f docker/Dockerfile -t ultralytics .`

---

## ğŸ“Š Additional Directories

### 12. `figures/` - Visualization Outputs
**Purpose**: Generated plots, charts, and images (auto-created during experiments).

```
figures/
â”œâ”€â”€ training_curves/                  # Loss/mAP plots
â”œâ”€â”€ confusion_matrices/               # Confusion matrices
â”œâ”€â”€ detection_samples/                # Sample predictions
â””â”€â”€ comparison_plots/                 # Cross-experiment comparisons
```

**Status**: May not exist initially, created by scripts.

---

### 13. `runs/` - YOLO CLI Outputs
**Purpose**: Default output directory for YOLO command-line runs.

```
runs/
â”œâ”€â”€ detect/                           # Detection runs
â”‚   â”œâ”€â”€ train/                        # Training outputs
â”‚   â”œâ”€â”€ val/                          # Validation outputs
â”‚   â””â”€â”€ predict/                      # Prediction outputs
â”œâ”€â”€ segment/                          # Segmentation runs
â”œâ”€â”€ classify/                         # Classification runs
â””â”€â”€ pose/                             # Pose estimation runs
```

**Note**:
- âš ï¸ Excluded from git (.gitignore)
- Use `experiments/` for organized long-term storage instead

---

## ğŸ”§ Configuration Files

### Root Level Configuration Files

| File | Purpose |
|------|---------|
| `pyproject.toml` | Python project metadata, dependencies, build system |
| `mkdocs.yml` | Documentation site configuration (MkDocs) |
| `.gitignore` | Git exclusion patterns (experiments/, runs/, *.pt, __pycache__, etc.) |
| `.pre-commit-config.yaml` | Pre-commit hooks for code quality |
| `CITATION.cff` | Citation information for academic use |
| `LICENSE` | AGPL-3.0 license text |
| `CONTRIBUTING.md` | Contribution guidelines for upstream |
| `SECURITY.md` | Security policy |

---

## ğŸ“¦ Model Weights (Root Directory)

```
/home/malezainia1/dev/ultralytics/
â”œâ”€â”€ yolo11n.pt                        # Nano (2.6M params, 24 MB)
â”œâ”€â”€ yolo11s.pt                        # Small (9.4M params, 38 MB)
â”œâ”€â”€ yolo11m.pt                        # Medium (20.1M params, 81 MB)
â”œâ”€â”€ yolo11l.pt                        # Large (25.3M params, 102 MB)
â””â”€â”€ yolo11x.pt                        # Extra-Large (56.9M params, 114 MB)
```

**Usage**: Loaded automatically by Ultralytics if present, otherwise downloaded from GitHub releases.

---

## ğŸš« Excluded from Git (.gitignore)

```
# Python
__pycache__/
*.pyc
*.pyo
*.egg-info/

# Experiments & Runs (too large)
experiments/
runs/

# Model Weights (download on-demand)
*.pt
*.pth
*.weights

# Datasets (download from Roboflow)
datasets/*/train/
datasets/*/valid/
datasets/*/test/

# Logs & Temporary Files
*.log
.DS_Store
Thumbs.db

# IDE & Environment
.vscode/
.idea/
*.swp
.env
```

---

## ğŸ”— Git Configuration

### Remotes

```bash
origin    https://github.com/lfleon9b/ultralytics_lleon.git  (your fork)
upstream  https://github.com/ultralytics/ultralytics.git     (original)
```

### Workflow

```bash
# Work on your fork
git add <files>
git commit -m "feat: description"
git push origin main

# Get upstream updates
git fetch upstream
git merge upstream/main
git push origin main
```

---

## ğŸ“ˆ Project Growth Metrics

| Metric | Count | Notes |
|--------|-------|-------|
| **Custom Scripts** | 10 | In `scripts/` |
| **Dataset Configs** | 3 | In `configs/` |
| **Datasets** | 3-4 | In `datasets/` (5,765+ images total) |
| **Experiments** | 15+ | In `experiments/` (5 models Ã— 3 datasets) |
| **Model Weights** | 5 | YOLO11 n/s/m/l/x (24-114 MB each) |
| **Documentation** | 5 | .claude.md, PROJECT_LOG.md, PROJECT_STRUCTURE.md, 2 Spanish reports |
| **External Scripts Reviewed** | 10 | In `external_review/` (172 KB) |
| **Total Lines of Custom Code** | ~2,000+ | Scripts + configs |
| **Total Lines of Documentation** | ~1,500+ | All .md files |

---

## ğŸ¯ Directory Usage Guidelines

### DO:
âœ… Add new scripts to `scripts/`
âœ… Add new dataset configs to `configs/`
âœ… Document experiments in `documents/`
âœ… Commit small files (<1MB): configs, scripts, docs
âœ… Update `.claude.md`, `PROJECT_LOG.md` regularly

### DON'T:
âŒ Modify `ultralytics/` core framework
âŒ Commit `experiments/` (too large)
âŒ Commit model weights `*.pt` (use Git LFS or exclude)
âŒ Commit datasets (use Roboflow/external hosting)
âŒ Hardcode absolute paths (use relative or config-based)

---

## ğŸ”„ Keeping Upstream in Sync

**Recommended Frequency**: Weekly (or when new features released)

```bash
# Check for updates
git fetch upstream

# View changes
git log upstream/main --oneline -10

# Merge (no conflicts expected in custom dirs)
git merge upstream/main

# Resolve any conflicts (rare if you don't modify ultralytics/)
# ...

# Push to your fork
git push origin main
```

**Recent Upstream Updates**:
- SAM3 model integration (Dec 2025)
- SystemLogger improvements
- Documentation fixes
- Export enhancements

---

## ğŸ“ Quick Reference

### File Locations Cheat Sheet

| What | Where |
|------|-------|
| Dataset configs | `configs/*.yaml` |
| Training scripts | `scripts/train_*.py` |
| Evaluation scripts | `scripts/evaluate_*.py` |
| Experiment results | `experiments/{dataset}/{model_config}/` |
| Best model weights | `experiments/{dataset}/{model_config}/weights/best.pt` |
| Training curves | `experiments/{dataset}/{model_config}/results.png` |
| Per-class metrics | `experiments/{dataset}/final_evaluation_report.csv` |
| Experiment reports | `documents/*.md` |
| Project documentation | `.claude.md`, `PROJECT_LOG.md`, `PROJECT_STRUCTURE.md` |
| External scripts | `external_review/maaferna_INIA_scripts/*.py` |
| Pre-trained models | Root directory: `yolo11{n,s,m,l,x}.pt` |

---

**Last Updated**: December 16, 2025
**Next Review**: After Session 3 (SAHI integration)
