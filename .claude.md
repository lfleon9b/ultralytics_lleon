# Ultralytics Agricultural Weed Detection Project

## Project Identity

This is the **Ultralytics YOLO framework (v8.3.235)** extended for agricultural precision farming research. The core focus is **weed species detection** using deep learning to enable targeted herbicide application and reduce agrochemical usage by 35-50%.

**Domain**: Computer vision for agriculture (precision farming, weed management)
**License**: AGPL-3.0 (https://ultralytics.com/license)
**Hardware**: Dual NVIDIA RTX 4090 GPUs with DDP (Distributed Data Parallel)
**Geographic Focus**: Santa Rosa region, Chile (Spanish documentation)

---

## Critical Conventions & Methodology

### DLM2 Methodology (MUST FOLLOW)
This project follows the **DLM2 research methodology** for weed detection:

**Core Principle**: Datasets are **pre-augmented externally**. Internal YOLO augmentation MUST be disabled to preserve radiometric fidelity.

**When training, ALWAYS disable these augmentations:**
```python
augment=False
mosaic=0.0
mixup=0.0
hsv_h=0.0, hsv_s=0.0, hsv_v=0.0  # Color jitter
degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0  # Geometric
flipud=0.0, fliplr=0.0  # Flipping
erasing=0.0, copy_paste=0.0  # Special augmentations
```

**Why**: Pre-augmented datasets maintain spatial context and spectral integrity critical for precision agriculture applications.

### Standard Training Parameters
- **Image Size**: 1024×1024px (fixed for all experiments)
- **Epochs**: 50 (standard)
- **Device**: `"0,1"` (DDP on both RTX 4090s)
- **Batch Sizes** (optimized for dual 4090 VRAM):
  - `yolo11n.pt`: 24
  - `yolo11s.pt`: 24
  - `yolo11m.pt`: 16
  - `yolo11l.pt`: 8-10
  - `yolo11x.pt`: 4

### Model Naming Convention
- **n** = Nano (smallest, fastest)
- **s** = Small
- **m** = Medium
- **l** = Large (current best for production)
- **x** = Extra-Large (most accurate, slowest)

---

## Project Structure

```
/home/malezainia1/dev/ultralytics/
├── ultralytics/              # Core YOLO framework library (DO NOT MODIFY)
├── configs/                  # Dataset configuration files (*.yaml)
│   ├── sr_dauca.yaml        # Single-class DAUCA specialist
│   ├── merge_varios_cultivos.yaml  # 6-class multi-weed model
│   └── lentils_v1.yaml      # Legacy 4-class configuration
├── datasets/                 # Agricultural datasets
│   ├── sr_dauca/            # Daucus carota specialist (70 train imgs)
│   ├── merge_varios_cultivos/  # Multi-weed unified (5,765 train imgs)
│   ├── lentils_v1/          # Legacy lentil weed detection
│   └── sr_dauca_extra/      # Additional DAUCA samples
├── experiments/              # Training results (DO NOT COMMIT)
│   └── {dataset_name}/
│       └── {model_config}/
│           ├── weights/best.pt, last.pt
│           ├── results.csv
│           └── [confusion matrices, curves, etc.]
├── scripts/                  # Custom training & evaluation scripts
│   ├── run_experiments.py   # Multi-model orchestrator
│   ├── train_sr_dauca.py    # Single dataset training
│   ├── evaluate_models.py   # Per-class metrics extraction
│   ├── compare_results.py   # Cross-experiment comparison
│   └── live_dashboard.py    # GPU monitoring (pynvml)
├── documents/                # Experiment reports (Spanish)
├── runs/                     # YOLO CLI outputs
├── [model weights]          # yolo11{n,s,m,l,x}.pt files (24-114MB)
└── .claude.md               # This file
```

---

## Key Datasets

### 1. merge_varios_cultivos (Multi-Weed Unified Model)
- **Classes (6)**: AMBEL, LENCU, LOLSS, POLAV, POLPE, RAPRA
- **Size**: 5,765 train / 181 val / 140 test images
- **Purpose**: Unified model for crop rotation scenarios
- **Best Results**: 81.9% mAP50 (val), 79.9% (test) with YOLO11l
- **Config**: `configs/merge_varios_cultivos.yaml`
- **Species Mapping**:
  - AMBEL = *Ambrosia artemisiifolia* (Ragweed)
  - LENCU = *Lentil* (Crop - must avoid spraying)
  - LOLSS = *Lolium* species
  - POLAV = *Polygonum aviculare* (Knotweed) ← **challenging class**
  - POLPE = *Polygonum persicaria*
  - RAPRA = *Raphanus raphanistrum* (Wild radish)

### 2. sr_dauca (DAUCA Specialist)
- **Classes (1)**: DAUCA (*Daucus carota* - Wild carrot)
- **Size**: 70 train / 3 val / 1 test images ← **SMALL DATASET**
- **Purpose**: High-precision spot-spraying for Santa Rosa region
- **Best Results**: 84.6% precision, 86.4% mAP50 with YOLO11l
- **Config**: `configs/sr_dauca.yaml`
- **Context**: Integrates with Sentinel-2 NDVI for weed patch validation

### 3. lentils_v1 (Legacy)
- **Classes (4)**: AMBEL, LENCU, POLAV, POLPE
- **Purpose**: Original multi-model comparison study
- **Config**: `configs/lentils_v1.yaml`

---

## Common Tasks

### 1. Run Multi-Model Experiment Suite
```bash
# Trains all 5 YOLO11 variants (n, s, m, l, x) with optimized batch sizes
python scripts/run_experiments.py

# Edit this file to change:
# - PROJECT_NAME (experiment folder)
# - DATA_CONFIG (which dataset)
# - EPOCHS, IMGSZ, DEVICE
```

### 2. Train Single Model
```bash
# Using custom script (includes DLM2 parameters)
python scripts/train_sr_dauca.py

# Using YOLO CLI directly (remember to disable augmentation!)
yolo detect train \
  data=configs/sr_dauca.yaml \
  model=yolo11l.pt \
  epochs=50 \
  imgsz=1024 \
  batch=10 \
  device=0,1 \
  project=experiments/sr_dauca \
  name=yolo11l_1024_e50_b10 \
  augment=False \
  mosaic=0.0 \
  mixup=0.0 \
  ...  # (see DLM2 parameters above)
```

### 3. Evaluate Trained Models
```bash
# Per-class metrics for all completed experiments
python scripts/evaluate_models.py

# Specific dataset evaluation (val + test splits)
python scripts/evaluate_sr_dauca.py
python scripts/evaluate_merge_varios.py

# Cross-experiment comparison table
python scripts/compare_results.py
```

### 4. Monitor Training
```bash
# Real-time GPU monitoring dashboard
python scripts/live_dashboard.py

# Live training curve plotting
python scripts/live_plot.py

# Or check TensorBoard logs
tensorboard --logdir experiments/
```

### 5. Inference on New Images
```python
from ultralytics import YOLO

# Load trained model
model = YOLO('experiments/sr_dauca/yolo11l_1024_e50_b10/weights/best.pt')

# Run inference
results = model.predict(
    source='path/to/images/',
    imgsz=1024,
    conf=0.25,  # Confidence threshold
    save=True,  # Save annotated images
    save_txt=True  # Save YOLO format labels
)
```

---

## Recent Experiments (December 2025)

### Multi-Crop Model (merge_varios_cultivos)
- **Model**: YOLO11l
- **Performance**: 81.9% mAP50 (val), 79.9% precision
- **Best Class**: LENCU (F1=0.90, mAP50=94.3%)
- **Challenging**: POLAV (mAP50=57.0% due to dataset imbalance)
- **Status**: ✅ Production-ready for multi-weed scenarios

### DAUCA Specialist (sr_dauca)
- **Model**: YOLO11l
- **Performance**: 84.6% precision, 79.1% recall, 86.4% mAP50
- **Limitation**: Small dataset (70 train images) - high performance but limited generalization
- **Status**: ✅ Deployed for Santa Rosa spot-spraying operations

### Findings
1. **YOLO11l** provides best accuracy/speed tradeoff for 1024px inference
2. **Class imbalance** significantly impacts POLAV performance
3. **Spatial autocorrelation** (Moran's I=0.667) confirms weed clustering patterns
4. **Multi-scale validation** (UAS + satellite) improves detection confidence

---

## Important Notes for Development

### DO:
✅ Always disable augmentation (DLM2 compliance)
✅ Use 1024×1024 image size for consistency
✅ Test on val split during development, reserve test split for final evaluation
✅ Use DDP (`device="0,1"`) for faster training on dual GPUs
✅ Commit configs, scripts, and documentation to git
✅ Document experiments in `documents/` with Spanish reports

### DON'T:
❌ Modify core `ultralytics/` library code (maintain upstream compatibility)
❌ Commit `experiments/` directory (too large, model weights excluded)
❌ Commit `runs/` directory (YOLO CLI temporary outputs)
❌ Add internal augmentation to training (breaks DLM2 methodology)
❌ Change image size without updating batch sizes
❌ Push model weights (*.pt files) to git (use Git LFS or exclude)

### Common Pitfalls:
1. **CUDA OOM**: Reduce batch size if GPU memory errors occur
2. **Augmentation creep**: Double-check training commands don't enable augmentation
3. **Path issues**: All dataset configs use absolute paths (`/home/malezainia1/...`)
4. **Small datasets**: sr_dauca has only 70 images - high variance expected
5. **DDP initialization**: First epoch may be slower due to distributed setup

---

## Key Dependencies

```toml
# From pyproject.toml
torch >= 1.8.0
torchvision >= 0.9.0
numpy >= 1.23.0
opencv-python >= 4.6.0
pillow >= 7.1.2
pyyaml >= 5.3.1
matplotlib >= 3.3.0
scipy >= 1.4.1
polars >= 0.20.0  # Data processing
psutil  # System monitoring
```

**Optional but recommended:**
- `wandb` - Weights & Biases logging
- `tensorboard` - Training visualization
- `albumentations >= 1.4.6` - External augmentation (pre-processing)
- `pynvml` - GPU monitoring (for live_dashboard.py)

---

## Integration Context

### Multi-Scale Weed Detection Pipeline
1. **UAS/Drone Imagery** (1.5mm/px resolution)
   → YOLO11l detection at 1024×1024px patches
   → Georeferenced bounding boxes

2. **Satellite Validation** (Sentinel-2, 10m resolution)
   → NDVI anomaly detection
   → Spatial autocorrelation analysis

3. **Prescription Maps**
   → Variable rate application (VRA) zones
   → Spot-spraying coordinates

### Roboflow Integration
- **Workspace**: `fia2024` (likely FIA research organization)
- **Projects**:
  - `santarosamosaic` → sr_dauca dataset
  - `mergevarios` → merge_varios_cultivos dataset
- Datasets can be updated via Roboflow CLI/API

---

## Documentation Standards

### Experiment Reports (Spanish)
Place comprehensive reports in `documents/` with:
- Methodology description (DLM2, model architecture)
- Dataset characteristics (size, class distribution, imbalance)
- Training configuration (hyperparameters, hardware)
- Results tables (precision, recall, F1, mAP50, mAP50-95)
- Per-class performance breakdown
- Confusion matrices and visualizations
- Limitations and recommendations

### Experiment Logs (Markdown)
Each experiment directory should have `experiment_log.md`:
```markdown
# Experiment: {Name}

## Configuration
- Model: YOLO11l
- Dataset: sr_dauca (70/3/1 split)
- Image Size: 1024×1024
- Batch Size: 10 (DDP)
- Epochs: 50
- Augmentation: Disabled (DLM2)

## Results
- Precision: 84.6%
- Recall: 79.1%
- mAP50: 86.4%

## Notes
- Small dataset limits generalization
- High precision suitable for spot-spraying
```

---

## Contact & Attribution

**Original Framework**: Ultralytics (https://github.com/ultralytics/ultralytics)
**Agricultural Extension**: This project (fia2024 research group)
**License**: AGPL-3.0 - If you use this in production, comply with license terms

For issues with core YOLO functionality, refer to Ultralytics documentation.
For agricultural pipeline questions, consult project-specific documentation in `documents/`.

---

## Quick Reference: File Locations

| What | Where |
|------|-------|
| **Dataset configs** | `configs/{dataset}.yaml` |
| **Training scripts** | `scripts/train_*.py` or `scripts/run_experiments.py` |
| **Evaluation scripts** | `scripts/evaluate_*.py` |
| **Model weights** | `experiments/{dataset}/{config}/weights/best.pt` |
| **Training results** | `experiments/{dataset}/{config}/results.csv` |
| **Experiment reports** | `documents/*.md` |
| **Pre-trained models** | Root directory: `yolo11{n,s,m,l,x}.pt` |

---

**Last Updated**: December 2025
**Project Status**: Active development - Multi-crop and specialist models deployed
